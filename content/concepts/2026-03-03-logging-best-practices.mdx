---
title: "Logging Best Practices"
slug: "2026-03-03-logging-best-practices"
date: "2026-03-03"
category: "Observability"
difficulty: "Beginner"
tags: ["Logging", "Observability", "Debugging", "Operations"]
description: "How to write logs that actually help you debug production issues -- structured logging, log levels, and what to log"
---

## Overview

Logs are your first line of defense when something goes wrong in production. Good logs tell you what happened, when, and why. Bad logs are noise that make it harder to find the signal. The difference is intentional, structured logging with the right context.

## Structured Logging

Structured logs (JSON) are machine-parseable. Text logs are not.

```python
# ❌ Unstructured: hard to parse, hard to search
logging.info(f"User {user_id} placed order {order_id} for ${total}")
# Output: 2026-03-03 10:15:42 INFO User 42 placed order 1001 for $99.99

# ✅ Structured: every field is queryable
import structlog
logger = structlog.get_logger()

logger.info("order.created",
    user_id=42,
    order_id=1001,
    total=99.99,
    currency="usd",
    items_count=3,
)
# Output: {"event": "order.created", "user_id": 42, "order_id": 1001,
#          "total": 99.99, "currency": "usd", "items_count": 3,
#          "timestamp": "2026-03-03T10:15:42Z", "level": "info"}
```

With structured logs, you can query in your log platform:
- `user_id=42` -- all actions by this user
- `event=order.created AND total>100` -- large orders
- `level=error AND service=payment` -- payment errors

## Log Levels

Use levels consistently across your team.

```python
# DEBUG: detailed info for developers during development
logger.debug("cache.lookup", key="user:42", hit=True)

# INFO: normal business events worth recording
logger.info("order.created", order_id=1001, user_id=42)

# WARNING: unexpected but handled situations
logger.warning("rate_limit.approaching", user_id=42, current=90, limit=100)

# ERROR: something failed that needs attention
logger.error("payment.failed", order_id=1001, error="card_declined")

# CRITICAL: system is unusable, immediate action needed
logger.critical("database.connection_lost", host="db-primary", retries_exhausted=True)
```

**Production default:** INFO and above. Enable DEBUG only when investigating issues.

## What to Log

### Do Log

```python
# Request lifecycle
logger.info("request.received", method="POST", path="/api/orders", request_id="abc-123")
logger.info("request.completed", request_id="abc-123", status=201, duration_ms=145)

# Business events
logger.info("user.registered", user_id=42, signup_method="google")
logger.info("payment.processed", order_id=1001, amount=99.99, provider="stripe")

# Errors with context
logger.error("email.send_failed",
    recipient="alice@example.com",
    template="order_confirmation",
    error="SMTP timeout",
    retry_count=2,
)

# Performance markers
logger.info("query.slow", query="SELECT ...", duration_ms=1200, table="orders")
```

### Don't Log

```python
# ❌ Passwords, tokens, API keys
logger.info("login", password=request.json["password"])  # NEVER

# ❌ Personal data (PII) unless required and compliant
logger.info("user", ssn=user.ssn, credit_card=user.card_number)  # NEVER

# ❌ Every iteration of a loop
for item in thousand_items:
    logger.debug("processing", item=item)  # Log summary instead

# ✅ Log the summary
logger.info("batch.processed", total=1000, succeeded=998, failed=2)
```

## Correlation IDs

Trace a single request across multiple services with a correlation ID.

```python
import uuid
from flask import g, request

@app.before_request
def set_request_id():
    g.request_id = request.headers.get("X-Request-ID", str(uuid.uuid4()))

@app.after_request
def add_request_id(response):
    response.headers["X-Request-ID"] = g.request_id
    return response

# Every log line includes the request ID
logger = structlog.get_logger()
logger = logger.bind(request_id=g.request_id)
logger.info("order.created", order_id=1001)
# {"event": "order.created", "order_id": 1001, "request_id": "abc-123-def"}
```

## Middleware for Automatic Request Logging

```python
import time

@app.before_request
def log_request_start():
    g.start_time = time.time()

@app.after_request
def log_request_end(response):
    duration = (time.time() - g.start_time) * 1000
    logger.info("request.completed",
        method=request.method,
        path=request.path,
        status=response.status_code,
        duration_ms=round(duration, 2),
        request_id=g.request_id,
    )
    return response
```

## Common Pitfalls

- **Logging sensitive data** -- Passwords, tokens, and PII in logs are a security incident waiting to happen.
- **Too verbose in production** -- DEBUG-level logging in production floods your storage and makes it impossible to find real issues.
- **No context** -- `"Error occurred"` is useless. Include IDs, parameters, and state.
- **String interpolation in log messages** -- Use structured fields instead. `"User 42 failed"` is harder to query than `event="login.failed", user_id=42`.

## Best Practices

- Use structured (JSON) logging everywhere
- Include a correlation/request ID in every log line
- Log at the right level consistently
- Include enough context to debug without reproducing
- Never log secrets, passwords, or tokens
- Set up log aggregation (ELK, Datadog, Loki) from day one
- Rotate and retain logs with a clear policy
